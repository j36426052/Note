# 分散式學習.md

## 簡單的架構

可以簡單分成

1. 資料平行化(Data Parallel)

依照一些規則將數據分配到不同的GPU上，並且每個GPU都有相同的模型架構，也就是會在每個GPU上複製一份相同的模型，各自進行訓練後，將計算結果合併，再進行參數更新。

參數更新的方式又分為同步及異步:

- 同步 (synchronous): 所有的 GPU 在訓練時會等待其他 GPU 計算完畢後，才會進行一次參數更新，因此訓練速度上會比使用異步的方式來得慢。但因為在更新參數時會合併其他計算結果，相當於增加了 batch size 的大小，對於訓練結果有一定的提升。
- 非同步、異步 (asynchronous): 每個 GPU 各自進行訓練和參數更新，不須等待其他 GPU 計算完畢。能夠提升訓練速度，但可能會產生 Slow and Stale Gradients (梯度失效、梯度過期) 問題，收斂過程較不穩定，訓練結果會比使用同步的方式差。

2. 模型平行化(Model Parallel)

簡單來說就是把模型給拆成很多個部分，並且放在不同的電腦

很明顯的，這次的畢業專題應該是已資料平行化為主，再考慮該如何把它拆成資料平行化

接著參考[這篇](https://blog.csdn.net/Julse/article/details/121474329)的程式碼

~~~py
# 安裝一些套件之類的
import tensorflow as tf
from tensorflow import keras

# Create a MirroredStrategy. 建立各種不同的Strategy
strategy = tf.distribute.MirroredStrategy()
print('Number of devices: {}'.format(strategy.num_replicas_in_sync))

# Open a strategy scope.
with strategy.scope():
  # Everything that creates variables should be under the strategy scope.
  # In general this is only model construction & `compile()`.
  model = Model(...)
  model.compile(...)

# Train the model on all available devices.
model.fit(train_dataset, validation_data=val_dataset, ...)

# Test the model on all available devices.
model.evaluate(test_dataset)
~~~

也可以參考[這篇](https://ithelp.ithome.com.tw/articles/10226066)
裡面有寫到Tensorflow 裡面不同的strategy

官方教學在[這篇](https://keras.io/guides/distributed_training/#singlehost-multidevice-synchronous-training)




## 參考資料

1. [分散式學習](https://medium.com/ching-i/pytorch-%E5%88%86%E6%95%A3%E5%BC%8F%E8%A8%93%E7%B7%B4-distributeddataparallel-%E6%A6%82%E5%BF%B5%E7%AF%87-8378e0ead77)

主要講概念還有pytorch給的東西，上面的簡單架構適用這個寫的

2. [一個線上課程](https://mastertalks.tw/products/python-dfa)

裡面看起來跟AI沒有甚麼關係，主要是把爬蟲分散開來，只有課綱沒啥內容，不用再點開
3. [Horoveod 一個分散式學習的套件的官網](https://horovod.readthedocs.io/en/stable/install_include.html)

看起來跟Keras沒甚麼關係

4. [ras 單機多卡](https://blog.csdn.net/Julse/article/details/121474329)
5. [keras 裡面要的東西](https://keras.io/guides/distributed_training/#singlehost-multidevice-synchronous-training)

